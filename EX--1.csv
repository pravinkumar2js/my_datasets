"import nltk
# nltk.download('punkt')
nltk.download('punkt_tab')
from nltk.tokenize import sent_tokenize
from nltk.tokenize import word_tokenize
text = ""Hello world! This is a tokenization example. The Natural Language Toolkit (NLTK) is a Python library used for working with human language data. Widely used in the field of Natural Language Processing (NLP), NLTK provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing and semantic reasoning.""
sentences = sent_tokenize(text)
print(""Sentence Tokenize\n"")
print(""Sentence Tokenization:"")
print(sentences)
words = word_tokenize(text)
print(""\nWord Tokenization:"")
print(words)"

"import nltk
from nltk.corpus import stopwords
from nltk import word_tokenize
# Download required datasets
nltk.download('punkt')
nltk.download('punkt_tab')
nltk.download('stopwords')
text = "This is a simple example showing how to remove stop words using NLTK in Python.so, i bring some words"
# Tokenize text
words = word_tokenize(text)
# Get English stop words
stop_words = set(stopwords.words('english'))
# Remove stop words
filtered_words = [word for word in words if word.lower() not in stop_words]
print("Original Words:")
print(words)
print("\nFiltered Words (Stop words removed):")
print(filtered_words)"
